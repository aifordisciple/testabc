"""
DEPRECATED: This module is deprecated and will be removed in a future version.

The CopilotOrchestrator class has been superseded by the unified Agent system.
Please use the Agent class from app.core.agent instead.

Migration guide:
- Use Agent.handle_request() instead of CopilotOrchestrator.analyze_request()
- Use ConversationMessage model instead of CopilotMessage
- Access the /copilot page as the single entry point

This module is kept temporarily for backward compatibility.
"""

import os
import json
from typing import Dict, Any, List, Optional
from uuid import UUID
from pydantic import BaseModel, Field
from sqlmodel import Session, select

from app.core.intent_parser import intent_parser, ParsedIntent
from app.core.fast_path import fast_path_handler, FastPathResult
from app.services.workflow_matcher import workflow_matcher, WorkflowMatch
from app.core.llm import llm_client
from app.models.user import User, Project, SampleSheet, Sample, File, ProjectFileLink, Analysis
from app.models.bio import WorkflowTemplate

class CopilotResponse(BaseModel):
    """Copilot ç»Ÿä¸€å“åº”"""
    mode: str = Field(
        ...,
        description="å“åº”æ¨¡å¼: workflow_match | code_generation | clarification_needed | query_result | error"
    )
    
    matched_workflows: Optional[List[WorkflowMatch]] = Field(
        default=None,
        description="åŒ¹é…åˆ°çš„æµç¨‹åˆ—è¡¨ (workflow_match æ¨¡å¼)"
    )
    
    generated_code: Optional[str] = Field(
        default=None,
        description="ç”Ÿæˆçš„ä»£ç  (code_generation æ¨¡å¼)"
    )
    generated_schema: Optional[str] = Field(
        default=None,
        description="ç”Ÿæˆçš„å‚æ•° Schema (code_generation æ¨¡å¼)"
    )
    generated_description: Optional[str] = Field(
        default=None,
        description="ç”Ÿæˆä»£ç çš„æè¿°"
    )
    
    query_data: Optional[Dict[str, Any]] = Field(
        default=None,
        description="æŸ¥è¯¢ç»“æœæ•°æ® (query_result æ¨¡å¼)"
    )
    
    parsed_intent: Optional[Dict[str, Any]] = Field(
        default=None,
        description="è§£æåçš„ç”¨æˆ·æ„å›¾"
    )
    
    explanation: str = Field(
        default="",
        description="AI çš„è§£é‡Šè¯´æ˜"
    )
    
    follow_up_questions: Optional[List[str]] = Field(
        default=None,
        description="éœ€è¦ç”¨æˆ·æ¾„æ¸…çš„é—®é¢˜ (clarification_needed æ¨¡å¼)"
    )
    
    available_sample_sheets: Optional[List[Dict[str, Any]]] = Field(
        default=None,
        description="é¡¹ç›®ä¸­å¯ç”¨çš„æ ·æœ¬è¡¨"
    )
    
    error_message: Optional[str] = Field(
        default=None,
        description="é”™è¯¯ä¿¡æ¯ (error æ¨¡å¼)"
    )

class CopilotOrchestrator:
    """
    Copilot ä¸»æ§åˆ¶å™¨
    åè°ƒæ„å›¾è§£æã€æµç¨‹åŒ¹é…ã€ä»£ç ç”Ÿæˆã€ä¿¡æ¯æŸ¥è¯¢ç­‰æ¨¡å—
    """
    
    MATCH_THRESHOLD = 0.65
    
    def __init__(self):
        print(f"ğŸ¤– [CopilotOrchestrator] Initialized with threshold: {self.MATCH_THRESHOLD}", flush=True)
    
    async def analyze_request(
        self,
        user_input: str,
        project_id: str,
        session: Session,
        user: User
    ) -> CopilotResponse:
        """
        åˆ†æç”¨æˆ·è¯·æ±‚å¹¶è¿”å›æ¨èæ–¹æ¡ˆ
        """
        print(f"\n{'='*60}", flush=True)
        print(f"ğŸ¬ [CopilotOrchestrator] Processing request for project {project_id}", flush=True)
        print(f"ğŸ“ User input: {user_input[:100]}...", flush=True)
        print(f"{'='*60}", flush=True)
        
        if fast_path_handler.can_handle(user_input):
            print(f"âš¡ [CopilotOrchestrator] Fast path detected", flush=True)
            fast_result = fast_path_handler.handle(user_input, project_id, session)
            if fast_result.handled:
                print(f"âš¡ [CopilotOrchestrator] Fast path handled successfully", flush=True)
                return CopilotResponse(
                    mode="fast_path",
                    query_data=fast_result.query_data,
                    explanation=fast_result.response
                )
        
        try:
            project = session.get(Project, UUID(project_id))
            if not project or project.owner_id != user.id:
                return CopilotResponse(
                    mode="error",
                    error_message="é¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®",
                    explanation="æ— æ³•æ‰¾åˆ°æŒ‡å®šçš„é¡¹ç›®ï¼Œè¯·ç¡®è®¤é¡¹ç›®IDæ˜¯å¦æ­£ç¡®ã€‚"
                )
            
            print(f"\nâ³ Step 1: Parsing intent...", flush=True)
            intent = intent_parser.parse(user_input)
            print(f"   âœ“ Intent type: {intent.intent_type}", flush=True)
            print(f"   âœ“ Confidence: {intent.confidence:.2%}", flush=True)
            
            if intent.intent_type == "query" and intent.query_target:
                return await self._handle_query_intent(intent, project, session)
            
            sample_sheets = session.exec(
                select(SampleSheet).where(SampleSheet.project_id == UUID(project_id))
            ).all()
            
            available_sheets = [
                {"id": str(sheet.id), "name": sheet.name, "description": sheet.description}
                for sheet in sample_sheets
            ]
            
            if intent.confidence < 0.3:
                return CopilotResponse(
                    mode="clarification_needed",
                    parsed_intent=intent.model_dump(),
                    explanation="æˆ‘éœ€è¦æ›´å¤šä¿¡æ¯æ¥ç†è§£æ‚¨çš„éœ€æ±‚ã€‚",
                    follow_up_questions=self._generate_clarification_questions(intent),
                    available_sample_sheets=available_sheets
                )
            
            print(f"\nâ³ Step 2: Matching workflows...", flush=True)
            matches = workflow_matcher.match(intent, session, top_k=3)
            
            if matches and matches[0].match_score >= self.MATCH_THRESHOLD:
                best_match = matches[0]
                
                if available_sheets:
                    best_match.inferred_params = workflow_matcher.infer_parameters_with_llm(
                        intent,
                        session.get(WorkflowTemplate, best_match.template_id),
                        available_sheets
                    )
                
                explanation = self._generate_match_explanation(intent, best_match)
                
                print(f"\nâœ… Mode: WORKFLOW_MATCH", flush=True)
                print(f"   Best match: {best_match.template_name} ({best_match.match_score:.2%})", flush=True)
                
                return CopilotResponse(
                    mode="workflow_match",
                    matched_workflows=matches,
                    parsed_intent=intent.model_dump(),
                    explanation=explanation,
                    available_sample_sheets=available_sheets
                )
            
            else:
                print(f"\nâ³ Step 3: Generating custom code...", flush=True)
                
                code_result = llm_client.generate_workflow(
                    messages=[{"role": "user", "content": user_input}],
                    mode="MODULE"
                )
                
                explanation = self._generate_code_explanation(intent, code_result)
                
                print(f"\nâœ… Mode: CODE_GENERATION", flush=True)
                
                return CopilotResponse(
                    mode="code_generation",
                    generated_code=code_result.get("main_nf", ""),
                    generated_schema=code_result.get("params_schema", "{}"),
                    generated_description=code_result.get("description", ""),
                    parsed_intent=intent.model_dump(),
                    explanation=explanation,
                    available_sample_sheets=available_sheets
                )
                
        except Exception as e:
            print(f"\nâŒ [CopilotOrchestrator] Error: {e}", flush=True)
            import traceback
            traceback.print_exc()
            
            return CopilotResponse(
                mode="error",
                error_message=str(e),
                explanation=f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
            )
    
    async def _handle_query_intent(
        self,
        intent: ParsedIntent,
        project: Project,
        session: Session
    ) -> CopilotResponse:
        """å¤„ç†æŸ¥è¯¢ç±»å‹çš„æ„å›¾"""
        query_target = intent.query_target
        project_id = project.id
        
        print(f"\nğŸ“Š Handling query: {query_target}", flush=True)
        
        if query_target == "files":
            return await self._query_files(project, session, intent)
        elif query_target == "samples":
            return await self._query_samples(project, session, intent)
        elif query_target == "analyses":
            return await self._query_analyses(project, session, intent)
        elif query_target == "workflow":
            return await self._query_workflows(project, session, intent)
        else:
            return CopilotResponse(
                mode="clarification_needed",
                parsed_intent=intent.model_dump(),
                explanation="æˆ‘ä¸å¤ªç¡®å®šæ‚¨æƒ³æŸ¥è¯¢ä»€ä¹ˆä¿¡æ¯ã€‚",
                follow_up_questions=[
                    "æ‚¨æƒ³æŸ¥è¯¢ä»€ä¹ˆä¿¡æ¯ï¼Ÿ",
                    "æ–‡ä»¶åˆ—è¡¨ (è¾“å…¥: æ–‡ä»¶)",
                    "æ ·æœ¬ä¿¡æ¯ (è¾“å…¥: æ ·æœ¬)",
                    "åˆ†æè®°å½• (è¾“å…¥: åˆ†æ)"
                ]
            )
    
    async def _query_files(
        self,
        project: Project,
        session: Session,
        intent: ParsedIntent
    ) -> CopilotResponse:
        """æŸ¥è¯¢é¡¹ç›®æ–‡ä»¶"""
        links = session.exec(
            select(ProjectFileLink).where(ProjectFileLink.project_id == project.id)
        ).all()
        
        file_ids = [link.file_id for link in links]
        files = []
        
        if file_ids:
            from sqlalchemy import or_
            file_records = session.exec(
                select(File).where(File.id.in_(file_ids))
            ).all()
            
            for f in file_records:
                file_info = {
                    "id": str(f.id),
                    "name": f.filename,
                    "size": f.size,
                    "type": f.content_type,
                    "is_directory": f.is_directory,
                    "uploaded_at": str(f.uploaded_at) if f.uploaded_at else None
                }
                
                if f.size:
                    if f.size < 1024:
                        file_info["size_readable"] = f"{f.size} B"
                    elif f.size < 1024 * 1024:
                        file_info["size_readable"] = f"{f.size / 1024:.1f} KB"
                    elif f.size < 1024 * 1024 * 1024:
                        file_info["size_readable"] = f"{f.size / (1024 * 1024):.1f} MB"
                    else:
                        file_info["size_readable"] = f"{f.size / (1024 * 1024 * 1024):.1f} GB"
                else:
                    file_info["size_readable"] = "-"
                
                files.append(file_info)
        
        if not files:
            explanation = f"ğŸ“ **é¡¹ç›® [{project.name}] ä¸­æš‚æ— æ–‡ä»¶**\n\n"
            explanation += "æ‚¨å¯ä»¥ç‚¹å‡»å·¦ä¾§çš„ **ä¸Šä¼ æ–‡ä»¶** æŒ‰é’®æ·»åŠ æ•°æ®æ–‡ä»¶ã€‚"
        else:
            explanation = f"ğŸ“ **é¡¹ç›® [{project.name}] ä¸­çš„æ–‡ä»¶åˆ—è¡¨** (å…± {len(files)} ä¸ª)\n\n"
            explanation += "| æ–‡ä»¶å | å¤§å° | ç±»å‹ |\n"
            explanation += "|--------|------|------|\n"
            
            for f in files[:20]:
                if not f.get("is_directory"):
                    name = f["name"][:30] + "..." if len(f["name"]) > 30 else f["name"]
                    explanation += f"| {name} | {f.get('size_readable', '-')} | {f.get('type', '-')} |\n"
            
            if len(files) > 20:
                explanation += f"\n*...è¿˜æœ‰ {len(files) - 20} ä¸ªæ–‡ä»¶æœªæ˜¾ç¤º*\n"
            
            dir_count = sum(1 for f in files if f.get("is_directory"))
            file_count = len(files) - dir_count
            explanation += f"\nğŸ“Š ç»Ÿè®¡: {file_count} ä¸ªæ–‡ä»¶, {dir_count} ä¸ªæ–‡ä»¶å¤¹"
        
        return CopilotResponse(
            mode="query_result",
            parsed_intent=intent.model_dump(),
            query_data={"files": files, "total": len(files)},
            explanation=explanation
        )
    
    async def _query_samples(
        self,
        project: Project,
        session: Session,
        intent: ParsedIntent
    ) -> CopilotResponse:
        """æŸ¥è¯¢æ ·æœ¬ä¿¡æ¯"""
        sample_sheets = session.exec(
            select(SampleSheet).where(SampleSheet.project_id == project.id)
        ).all()
        
        all_samples = []
        sheet_info = []
        
        for sheet in sample_sheets:
            samples = session.exec(
                select(Sample).where(Sample.sample_sheet_id == sheet.id)
            ).all()
            
            sheet_info.append({
                "id": str(sheet.id),
                "name": sheet.name,
                "description": sheet.description,
                "sample_count": len(samples)
            })
            
            for s in samples:
                all_samples.append({
                    "id": str(s.id),
                    "name": s.name,
                    "group": s.group,
                    "replicate": s.replicate,
                    "sheet_name": sheet.name
                })
        
        if not sample_sheets:
            explanation = f"ğŸ§¬ **é¡¹ç›® [{project.name}] ä¸­æš‚æ— æ ·æœ¬è¡¨**\n\n"
            explanation += "æ‚¨å¯ä»¥å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼Œç„¶ååœ¨ **æ ·æœ¬ç®¡ç†** ä¸­åˆ›å»ºæ ·æœ¬è¡¨ã€‚"
        else:
            explanation = f"ğŸ§¬ **é¡¹ç›® [{project.name}] ä¸­çš„æ ·æœ¬ä¿¡æ¯**\n\n"
            
            for sheet in sheet_info:
                explanation += f"### ğŸ“‹ {sheet['name']}"
                if sheet['description']:
                    explanation += f" - {sheet['description']}"
                explanation += f" ({sheet['sample_count']} ä¸ªæ ·æœ¬)\n\n"
            
            if all_samples:
                explanation += "| æ ·æœ¬å | åˆ†ç»„ | é‡å¤ | æ ·æœ¬è¡¨ |\n"
                explanation += "|--------|------|------|--------|\n"
                for s in all_samples[:15]:
                    explanation += f"| {s['name']} | {s['group']} | {s['replicate']} | {s['sheet_name']} |\n"
                
                if len(all_samples) > 15:
                    explanation += f"\n*...è¿˜æœ‰ {len(all_samples) - 15} ä¸ªæ ·æœ¬*\n"
        
        return CopilotResponse(
            mode="query_result",
            parsed_intent=intent.model_dump(),
            query_data={"sample_sheets": sheet_info, "samples": all_samples, "total": len(all_samples)},
            explanation=explanation
        )
    
    async def _query_analyses(
        self,
        project: Project,
        session: Session,
        intent: ParsedIntent
    ) -> CopilotResponse:
        """æŸ¥è¯¢åˆ†æä»»åŠ¡"""
        from sqlalchemy import desc
        
        analyses = session.exec(
            select(Analysis)
            .where(Analysis.project_id == project.id)
            .order_by(desc(Analysis.start_time))
            .limit(20)
        ).all()
        
        if not analyses:
            explanation = f"ğŸ“Š **é¡¹ç›® [{project.name}] ä¸­æš‚æ— åˆ†æä»»åŠ¡**\n\n"
            explanation += "æ‚¨å¯ä»¥å‘Šè¯‰æˆ‘æƒ³è¦è¿›è¡Œä»€ä¹ˆåˆ†æï¼Œæˆ‘ä¼šå¸®æ‚¨æ‰¾åˆ°åˆé€‚çš„æµç¨‹ã€‚"
        else:
            explanation = f"ğŸ“Š **é¡¹ç›® [{project.name}] ä¸­çš„åˆ†æè®°å½•** (æœ€è¿‘ {len(analyses)} æ¡)\n\n"
            explanation += "| ä»»åŠ¡ | æµç¨‹ | çŠ¶æ€ | å¼€å§‹æ—¶é—´ |\n"
            explanation += "|------|------|------|----------|\n"
            
            status_emoji = {
                "pending": "â³",
                "running": "ğŸ”„",
                "completed": "âœ…",
                "failed": "âŒ",
                "error": "âŒ"
            }
            
            for a in analyses:
                status = status_emoji.get(a.status, "â“")
                start = a.start_time.strftime("%m-%d %H:%M") if a.start_time else "-"
                explanation += f"| {str(a.id)[:8]}... | {a.workflow} | {status} {a.status} | {start} |\n"
        
        return CopilotResponse(
            mode="query_result",
            parsed_intent=intent.model_dump(),
            query_data={"analyses": [{"id": str(a.id), "workflow": a.workflow, "status": a.status, "start_time": str(a.start_time)} for a in analyses]},
            explanation=explanation
        )
    
    async def _query_workflows(
        self,
        project: Project,
        session: Session,
        intent: ParsedIntent
    ) -> CopilotResponse:
        """æŸ¥è¯¢å¯ç”¨æµç¨‹"""
        templates = session.exec(
            select(WorkflowTemplate).where(WorkflowTemplate.is_public == True)
        ).all()
        
        if not templates:
            explanation = "ğŸ“ **æš‚æ— å¯ç”¨çš„åˆ†ææµç¨‹**\n\n"
            explanation += "ç³»ç»Ÿç®¡ç†å‘˜å°šæœªé…ç½®åˆ†ææµç¨‹æ¨¡æ¿ã€‚"
        else:
            explanation = f"ğŸ“ **å¯ç”¨çš„åˆ†ææµç¨‹** (å…± {len(templates)} ä¸ª)\n\n"
            
            for t in templates[:15]:
                explanation += f"### ğŸ”¬ {t.name}\n"
                if t.description:
                    desc = t.description[:100] + "..." if len(t.description) > 100 else t.description
                    explanation += f"{desc}\n"
                explanation += f"- ç±»å‹: {t.workflow_type}\n"
                if t.category:
                    explanation += f"- åˆ†ç±»: {t.category}"
                    if t.subcategory:
                        explanation += f" / {t.subcategory}"
                    explanation += "\n"
                explanation += "\n"
        
        return CopilotResponse(
            mode="query_result",
            parsed_intent=intent.model_dump(),
            query_data={"workflows": [{"id": str(t.id), "name": t.name, "type": t.workflow_type, "category": t.category} for t in templates]},
            explanation=explanation
        )
    
    def _generate_clarification_questions(self, intent: ParsedIntent) -> List[str]:
        """ç”Ÿæˆæ¾„æ¸…é—®é¢˜"""
        questions = []
        
        if not intent.analysis_type or intent.analysis_type == "Custom Analysis":
            questions.append("æ‚¨æƒ³è¿›è¡Œä»€ä¹ˆç±»å‹çš„åˆ†æï¼Ÿä¾‹å¦‚ï¼šRNA-Seqè´¨æ§ã€å·®å¼‚è¡¨è¾¾åˆ†æã€å•ç»†èƒåˆ†æç­‰")
        
        if not intent.data_type:
            questions.append("æ‚¨çš„æ•°æ®æ˜¯ä»€ä¹ˆç±»å‹ï¼Ÿä¾‹å¦‚ï¼šRNA-Seqã€ChIP-Seqã€ATAC-Seqç­‰")
        
        if not intent.expected_outputs:
            questions.append("æ‚¨å¸Œæœ›å¾—åˆ°ä»€ä¹ˆæ ·çš„è¾“å‡ºç»“æœï¼Ÿä¾‹å¦‚ï¼šè´¨æ§æŠ¥å‘Šã€å·®å¼‚åŸºå› åˆ—è¡¨ã€ç«å±±å›¾ç­‰")
        
        return questions[:3]
    
    def _generate_match_explanation(self, intent: ParsedIntent, match: WorkflowMatch) -> str:
        """ç”ŸæˆåŒ¹é…è¯´æ˜"""
        explanation = f"ğŸ¯ **å·²è¯†åˆ«åˆ†æç±»å‹**: {intent.analysis_type}\n\n"
        
        if match.match_score >= 0.8:
            explanation += f"âœ… **é«˜åº¦åŒ¹é…çš„æµç¨‹**: {match.template_name}\n\n"
            explanation += f"è¯¥æµç¨‹å¯ä»¥å¾ˆå¥½åœ°æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚{match.description}\n\n"
        elif match.match_score >= 0.65:
            explanation += f"âœ“ **æ¨èæµç¨‹**: {match.template_name}\n\n"
            explanation += f"è¯¥æµç¨‹ä¸æ‚¨çš„éœ€æ±‚è¾ƒä¸ºåŒ¹é…ã€‚{match.description}\n\n"
        else:
            explanation += f"â„¹ï¸ **å¯èƒ½ç›¸å…³çš„æµç¨‹**: {match.template_name}\n\n"
        
        if match.match_reason:
            explanation += f"ğŸ“‹ **åŒ¹é…åŸå› **: {match.match_reason}\n\n"
        
        if match.inferred_params:
            explanation += "âš™ï¸ **æ¨èå‚æ•°**:\n"
            for key, value in match.inferred_params.items():
                if value is not None and value != "":
                    explanation += f"- {key}: {value}\n"
        
        return explanation
    
    def _generate_code_explanation(self, intent: ParsedIntent, code_result: Dict) -> str:
        """ç”Ÿæˆä»£ç è¯´æ˜"""
        explanation = f"ğŸ¯ **å·²è¯†åˆ«åˆ†æç±»å‹**: {intent.analysis_type}\n\n"
        explanation += "ğŸ“ **å·²ä¸ºæ‚¨ç”Ÿæˆè‡ªå®šä¹‰åˆ†æä»£ç **\n\n"
        
        if code_result.get("description"):
            explanation += f"**åŠŸèƒ½æè¿°**: {code_result['description']}\n\n"
        
        if code_result.get("explanation"):
            explanation += f"**å®ç°è¯´æ˜**: {code_result['explanation']}\n\n"
        
        explanation += "âš ï¸ ç”±äºæ²¡æœ‰æ‰¾åˆ°å®Œå…¨åŒ¹é…çš„é¢„ç½®æµç¨‹ï¼Œæˆ‘ä¸ºæ‚¨ç”Ÿæˆäº†è‡ªå®šä¹‰ä»£ç ã€‚\n"
        explanation += "è¯·åœ¨æ‰§è¡Œå‰æ£€æŸ¥ä»£ç å’Œå‚æ•°æ˜¯å¦ç¬¦åˆæ‚¨çš„éœ€æ±‚ã€‚\n"
        
        return explanation

copilot_orchestrator = CopilotOrchestrator()
