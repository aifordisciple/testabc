import os
import json
import re
from typing import List, Dict, Any, Optional
from uuid import UUID
from pydantic import BaseModel, Field
from sqlmodel import Session, select, or_
from openai import OpenAI

from app.models.bio import WorkflowTemplate
from app.core.intent_parser import ParsedIntent

class WorkflowMatch(BaseModel):
    """åŒ¹é…åˆ°çš„æµç¨‹"""
    template_id: UUID = Field(..., description="æµç¨‹æ¨¡æ¿ID")
    template_name: str = Field(..., description="æµç¨‹åç§°")
    description: str = Field(default="", description="æµç¨‹æè¿°")
    workflow_type: str = Field(default="PIPELINE", description="æµç¨‹ç±»å‹")
    match_score: float = Field(..., ge=0.0, le=1.0, description="åŒ¹é…åº¦ 0-1")
    match_reason: str = Field(default="", description="åŒ¹é…åŸå› è¯´æ˜")
    inferred_params: Dict[str, Any] = Field(default_factory=dict, description="æ¨æ–­çš„å‚æ•°")
    params_schema: Dict[str, Any] = Field(default_factory=dict, description="å‚æ•°å®šä¹‰")
    source_code: Optional[str] = Field(default=None, description="æµç¨‹æºä»£ç ")

class WorkflowMatcher:
    """
    æµç¨‹åŒ¹é…æœåŠ¡
    ä½¿ç”¨æ··åˆåŒ¹é…ç­–ç•¥æ‰¾åˆ°æœ€é€‚åˆç”¨æˆ·éœ€æ±‚çš„æµç¨‹æ¨¡æ¿
    """
    
    TYPE_MAPPINGS = {
        "RNA-Seq QC": ["rnaseq_qc", "fastqc", "quality control", "è´¨æ§", "è´¨é‡æ§åˆ¶"],
        "RNA-Seq Differential Expression": ["differential", "å·®å¼‚è¡¨è¾¾", "degs", "deseq", "edger"],
        "scRNA-Seq Analysis": ["scrnaseq", "single cell", "å•ç»†èƒ", "seurat", "scanpy"],
        "ChIP-Seq Peak Calling": ["chipseq", "peak calling", "macs", "chip-seq"],
        "ATAC-Seq Analysis": ["atacseq", "atac-seq", "chromatin accessibility"],
        "Variant Calling": ["variant", "gatk", "snv", "cnv", "çªå˜æ£€æµ‹", "å˜å¼‚æ£€æµ‹"],
        "Genome Assembly": ["assembly", "ç»„è£…", "denovo"],
        "Proteomics Analysis": ["proteomics", "è›‹ç™½è´¨ç»„", "mass spec"],
        "Methylation Analysis": ["methylation", "ç”²åŸºåŒ–", "bisulfite"],
        "Copy Number Variation": ["cnv", "copy number", "æ‹·è´æ•°"],
        "Gene Set Enrichment": ["enrichment", "go", "kegg", "å¯Œé›†åˆ†æ"],
        "Pathway Analysis": ["pathway", "é€šè·¯åˆ†æ"],
    }
    
    
    def __init__(self):
        # Use unified llm_client singleton
        from app.core.llm import get_llm_client
        
        client = get_llm_client()
        self.base_url = client.config.base_url
        self.api_key = client.config.api_key
        self.model = client.config.model
        self.embed_model = client.config.embed_model
        
        # Use singleton's embed client
        self.embed_client = client.embed_client

    
    def get_embedding(self, text: str) -> List[float]:
        """è·å–æ–‡æœ¬çš„å‘é‡åµŒå…¥"""
        try:
            response = self.embed_client.embeddings.create(
                input=text.replace("\n", " "),
                model=self.embed_model
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âš ï¸ [WorkflowMatcher] Embedding error: {e}", flush=True)
            return []
    
    def match(
        self,
        intent: ParsedIntent,
        session: Session,
        top_k: int = 3
    ) -> List[WorkflowMatch]:
        """
        åŒ¹é…æœ€é€‚åˆçš„æµç¨‹æ¨¡æ¿
        
        Args:
            intent: è§£æåçš„ç”¨æˆ·æ„å›¾
            session: æ•°æ®åº“ä¼šè¯
            top_k: è¿”å›å‰Kä¸ªåŒ¹é…ç»“æœ
            
        Returns:
            List[WorkflowMatch]: åŒ¹é…ç»“æœåˆ—è¡¨ï¼ŒæŒ‰åˆ†æ•°é™åºæ’åˆ—
        """
        print(f"ğŸ” [WorkflowMatcher] Matching for: {intent.analysis_type}", flush=True)
        
        templates = session.exec(
            select(WorkflowTemplate).where(WorkflowTemplate.is_public == True)
        ).all()
        
        if not templates:
            print("âš ï¸ [WorkflowMatcher] No templates found in database", flush=True)
            return []
        
        scored_matches = []
        
        # é¢„å¤„ç†: æ”¶é›†æœ‰embeddingçš„æ¨¡æ¿
        templates_with_embedding = {t.id: t.embedding for t in templates if t.embedding}
        
        for template in templates:
            base_score, reason = self._calculate_match_score(intent, template)
            
            # å‘é‡ç›¸ä¼¼åº¦åŠ åˆ†
            vector_boost = 0.0
            if template.id in templates_with_embedding:
                query_text = f"{intent.analysis_type} {' '.join(intent.keywords)}"
                vec = templates_with_embedding[template.id]
                sim = self._cosine_similarity(query_text, vec) if vec else 0.0
                if sim > 0.5:
                    vector_boost = min(0.3, (sim - 0.5) * 0.6)
                    reason = f"{reason} | å‘é‡:{sim:.2f}" if reason else f"å‘é‡ç›¸ä¼¼åº¦:{sim:.2f}"
            
            total_score = base_score + vector_boost
            
            if total_score > 0.3:
                scored_matches.append((template, total_score, reason))
        
        for template in templates:
            score, reason = self._calculate_match_score(intent, template)
            
            if score > 0.3:
                scored_matches.append((template, score, reason))
        
        scored_matches.sort(key=lambda x: x[1], reverse=True)
        
        results = []
        for template, score, reason in scored_matches[:top_k]:
            inferred_params = self._infer_parameters(intent, template)
            
            params_schema = {}
            if template.params_schema:
                try:
                    params_schema = json.loads(template.params_schema)
                except:
                    pass
            
            results.append(WorkflowMatch(
                template_id=template.id,
                template_name=template.name,
                description=template.description or "",
                workflow_type=template.workflow_type,
                match_score=round(score, 3),
                match_reason=reason,
                inferred_params=inferred_params,
                params_schema=params_schema,
                source_code=template.source_code
            ))
        
        print(f"âœ… [WorkflowMatcher] Found {len(results)} matches", flush=True)
        for r in results:
            print(f"   - {r.template_name}: {r.match_score:.2%}", flush=True)
        
        return results
    
    def _calculate_match_score(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate
    ) -> tuple[float, str]:
        """
        è®¡ç®—ç»¼åˆåŒ¹é…åˆ†æ•°
        
        Returns:
            tuple[float, str]: (åŒ¹é…åˆ†æ•°, åŒ¹é…åŸå› )
        """
        scores = []
        reasons = []
        
        type_score, type_reason = self._type_matching_score(intent, template)
        scores.append(type_score * 0.4)
        if type_reason:
            reasons.append(type_reason)
        
        keyword_score, keyword_reason = self._keyword_matching_score(intent, template)
        scores.append(keyword_score * 0.3)
        if keyword_reason:
            reasons.append(keyword_reason)
        
        category_score, category_reason = self._category_matching_score(intent, template)
        scores.append(category_score * 0.2)
        if category_reason:
            reasons.append(category_reason)
        
        name_score, name_reason = self._name_matching_score(intent, template)
        scores.append(name_score * 0.1)
        if name_reason:
            reasons.append(name_reason)
        
        total_score = sum(scores)
        reason = "; ".join(reasons) if reasons else "åŸºç¡€åŒ¹é…"
        
        return total_score, reason
    
    def _type_matching_score(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate
    ) -> tuple[float, str]:
        """åˆ†æç±»å‹åŒ¹é…è¯„åˆ†"""
        analysis_type = intent.analysis_type.lower()
        template_name = template.name.lower()
        template_desc = (template.description or "").lower()
        script_path = (template.script_path or "").lower()
        
        if analysis_type in self.TYPE_MAPPINGS:
            keywords = self.TYPE_MAPPINGS[analysis_type]
            for kw in keywords:
                if kw.lower() in template_name or kw.lower() in template_desc or kw.lower() in script_path:
                    return 1.0, f"åˆ†æç±»å‹åŒ¹é…: {intent.analysis_type}"
        
        type_keywords = intent.analysis_type.lower().replace("-", " ").replace("_", " ").split()
        for kw in type_keywords:
            if len(kw) > 2 and kw in template_name:
                return 0.7, f"ç±»å‹å…³é”®è¯åŒ¹é…: {kw}"
        
        return 0.0, ""
    
    def _keyword_matching_score(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate
    ) -> tuple[float, str]:
        """å…³é”®è¯åŒ¹é…è¯„åˆ†"""
        if not intent.keywords:
            return 0.0, ""
        
        template_text = f"{template.name} {template.description or ''} {template.script_path or ''}".lower()
        
        matched_keywords = []
        for kw in intent.keywords:
            if kw.lower() in template_text:
                matched_keywords.append(kw)
        
        if matched_keywords:
            score = len(matched_keywords) / len(intent.keywords)
            return min(score, 1.0), f"å…³é”®è¯åŒ¹é…: {', '.join(matched_keywords[:3])}"
        
        return 0.0, ""
    
    def _category_matching_score(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate
    ) -> tuple[float, str]:
        """åˆ†ç±»åŒ¹é…è¯„åˆ†"""
        analysis_type = intent.analysis_type.lower()
        category = (template.category or "").lower()
        subcategory = (template.subcategory or "").lower()
        
        type_category_map = {
            "qc": ["quality control", "è´¨æ§", "qc"],
            "differential": ["differential", "å·®å¼‚"],
            "analysis": ["analysis", "åˆ†æ"],
        }
        
        for type_kw, category_kws in type_category_map.items():
            if type_kw in analysis_type:
                for cat_kw in category_kws:
                    if cat_kw in category or cat_kw in subcategory:
                        return 0.8, f"åˆ†ç±»åŒ¹é…: {template.category}"
        
        return 0.0, ""
    
    def _name_matching_score(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate
    ) -> tuple[float, str]:
        """åç§°ç›´æ¥åŒ¹é…è¯„åˆ†"""
        analysis_type = intent.analysis_type.lower()
        template_name = template.name.lower()
        
        type_words = set(re.findall(r'\w+', analysis_type))
        name_words = set(re.findall(r'\w+', template_name))
        
        common_words = type_words & name_words
        if common_words:
            score = len(common_words) / max(len(type_words), 1)
            return score, f"åç§°åŒ¹é…"
        
        return 0.0, ""
    
    def _infer_parameters(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate
    ) -> Dict[str, Any]:
        """
        ä»ç”¨æˆ·æ„å›¾æ¨æ–­æµç¨‹å‚æ•°
        """
        params = {}
        
        if not template.params_schema:
            return params
        
        try:
            schema = json.loads(template.params_schema)
            properties = schema.get("properties", {})
            
            for param_name, param_def in properties.items():
                param_type = param_def.get("type", "string")
                default_val = param_def.get("default")
                
                if param_type == "boolean":
                    for kw in ["skip", "ä¸", "no", "disable"]:
                        if kw in param_name.lower() or kw in str(default_val).lower():
                            params[param_name] = False
                            break
                
                elif param_type == "string":
                    if default_val is not None:
                        params[param_name] = default_val
                
                elif param_type in ["integer", "number"]:
                    if default_val is not None:
                        params[param_name] = default_val
            
            for output in intent.expected_outputs:
                if "skip" in output.lower():
                    for param_name in properties:
                        if "skip" in param_name.lower():
                            params[param_name] = True
                            
        except Exception as e:
            print(f"âš ï¸ [WorkflowMatcher] Parameter inference error: {e}", flush=True)
        
        return params
    
    def infer_parameters_with_llm(
        self,
        intent: ParsedIntent,
        template: WorkflowTemplate,
        available_samples: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        ä½¿ç”¨ LLM æ™ºèƒ½æ¨æ–­å‚æ•°
        """
        if not template.params_schema:
            return {}
        
        try:
            schema = json.loads(template.params_schema)
        except:
            return {}
        
        import instructor
        client = instructor.from_openai(
            OpenAI(base_url=self.base_url, api_key=self.api_key),
            mode=instructor.Mode.JSON
        )
        
        class ParameterInference(BaseModel):
            parameters: Dict[str, Any] = Field(default_factory=dict, description="æ¨æ–­çš„å‚æ•°å€¼")
            reasoning: str = Field(default="", description="æ¨æ–­ç†ç”±")
        
        context = f"""
ç”¨æˆ·éœ€æ±‚: {intent.raw_description}
åˆ†æç±»å‹: {intent.analysis_type}
æœŸæœ›è¾“å‡º: {intent.expected_outputs}
ç‰©ç§: {intent.organism or 'æœªæŒ‡å®š'}

æµç¨‹æ¨¡æ¿: {template.name}
æµç¨‹æè¿°: {template.description or 'æ— '}

å‚æ•°å®šä¹‰ (JSON Schema):
{json.dumps(schema, ensure_ascii=False, indent=2)}
"""
        
        if available_samples:
            context += f"\nå¯ç”¨æ ·æœ¬æ•°é‡: {len(available_samples)}\n"
        
        try:
            result = client.chat.completions.create(
                model=self.model,
                response_model=ParameterInference,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªç”Ÿç‰©ä¿¡æ¯å­¦å‚æ•°é…ç½®ä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨æ–­æœ€åˆé€‚çš„å‚æ•°å€¼ã€‚"},
                    {"role": "user", "content": context}
                ],
                temperature=0.1,
                max_retries=2
            )
            
            print(f"ğŸ§  [WorkflowMatcher] LLM inferred params: {result.parameters}", flush=True)
            return result.parameters
            
        except Exception as e:
            print(f"âš ï¸ [WorkflowMatcher] LLM inference error: {e}", flush=True)
            return self._infer_parameters(intent, template)
    
    def _cosine_similarity(self, text: str, embedding: List[float]) -> float:
        """è®¡ç®—æ–‡æœ¬ä¸å‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦"""
        if not embedding:
            return 0.0
        try:
            vec = self.get_embedding(text)
            if not vec:
                return 0.0
            dot = sum(a * b for a, b in zip(vec, embedding))
            norm1 = sum(a * a for a in vec) ** 0.5
            norm2 = sum(b * b for b in embedding) ** 0.5
            if norm1 == 0 or norm2 == 0:
                return 0.0
            return dot / (norm1 * norm2)
        except Exception as e:
            print(f"âš ï¸ Vector similarity error: {e}", flush=True)
            return 0.0

workflow_matcher = WorkflowMatcher()

workflow_matcher = WorkflowMatcher()
